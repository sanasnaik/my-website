<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="styles.css">
        <title>Sana Naik</title>
        <link rel="icon" type="image/x-icon" href="/images/moon.png">
    </head>
    <body>
        <div class="header">
            <div class="logo">
                <a href="index.html">Sana Naik</a>
            </div>
            <div class="right-links">
                <ul>
                    <li><a href="about.html">Resume</a></li>
                    <li><a href="projects.html">Projects</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </div>
        </div>
        <div class="content">
            <div class="top">
                <div class="text">
                    <h1>Projects</h1>
                </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://github.com/sanasnaik/laqm-data-collection">Aresty Research Assistant Project</a></h2>
                <p>
                Created modular Python code that configures, collects, and displays live data synchronously from the Lock In Amplifier (SR830) and Physical Property Measurement System (PPMS) instruments at the Rutgers Lab of Artificial Quantum Materials. <br> <br>
                Helps physicists interface with laboratory equipment and gather and analyze data from experiments on  quantum materials (see research poster for details!)
                <br><br>Functions: creates a GUI, records, plots, and stores data from the SR830 and PPMS, communicates with and configures the machines. 
                <br><br>Tools: Numpy, Pandas, MatPlotLib, Pyvisa, MultiPyVu, Pymeasure, and more.
                <br><br>Nontechnical skills: research logging, creating code documentation and usage guides, communication, leadership, presentation.
                <br><br><a href="https://docs.google.com/presentation/d/1EhYaRyZPHn2rgJ5g5TQhWGQghaYGSzBVgRnuUIDbZLI/edit?usp=sharing">Research Poster</a>
                </p>
                </div>
                <img src="images/research1.JPG">
                <img src="images/research2.JPG">
            </div>
            <div class="project">
                <div>
                    <h2><a href="https://github.com/sanasnaik/LeNet-5-Pytorch-Classifier">LeNet-5 Pytorch Model - Image Classifier</a></h2>
                    <p>
                        Based on the paper "Gradient-Based Learning Applied to Document Recognition" by Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner.
                        <br><br>We recreated the LeNet-5 model, which is an image classifier for the numerical digits (0-9), and  created an improved version
                        of the model to better distinguish the digits and learn hidden patterns.
                        
                        <br><br>For the RBF parameters, we used the DIGIT dataset. Each digit (0‚Äì9) had several small 7√ó12 grayscale images. To generate the RBF prototypes, we loaded the image tensors from each digit‚Äôs directory, resized them to 7√ó12, and averaged all images for a given digit to create a representative prototype. This averaging approach reduces noise and yields a smooth, centralized prototype for each class, improving the robustness of the RBF classifier. These 84-dimensional flattened prototypes serve as the reference centers for the squared Euclidean distance computation in the RBF output layer.  
                        
                        <img src="images/lenet-images/bitmap_prototypes.png" alt="Bitmap prototypes for digits 0-9"> 
                        <br>Figure 1: Generated 7√ó12 bitmap prototypes for digits 0‚Äì9. Each image represents the average
                        shape of a digit from the DIGIT dataset.    

                        <br><br><h3>Original LeNet Model</h3>
                        <br>Training
                        <br>Data: MNIST dataset from torchvision.datasets, resized from 28x28 to 32x32 using padding.  
                        <br>Batch size: 1  
                        <br>Loss function: Margin loss using equation (9) from the paper listed in the header.  
                        <br>Gradient descent: SGD optimizer with learning rate = 0.01 and momentum = 0.9  
                        <br>Tracking: Train and test error tracked at every epoch.  
                        <br>Epochs: 20    
                        <br>
                        <img src="images/lenet-images/Error_Rate_Graph.png" alt="Training and test error rate of the original LeNet-5">
                        <br>Figure 2: Training and Test Error Across Epochs (Original MNIST)    

                        <br><br>Performance Evaluation
                        <l>
                            <li>Confusion matrix (10√ó10) for test set at epoch 20.  
                            <li>Most confusing digits identified based on max incorrect predictions.  
                            <li>Final error rates at epoch 20:  
                            <li>Train error: 0.63%
                            <li>Test error: 1.05%
                        </l>

                        <br><img src="images/lenet-images/Confusion_Matrix.png" alt="Confusion Matrix on Original MNIST Test Set">
                        <br>Figure 3: Confusion Matrix on Original MNIST Test Set
                        <br><img src="images/lenet-images/Most_Confusing_Example.png" alt="Most Confusing Examples per Digit (True Label vs. Predicted Label)">
                        <br>Figure 4: Most Confusing Examples per Digit (True Label vs. Predicted Label)    

                        <br><br><h3>LeNet Modification for Unseen Data</h3>
                        <br>We implemented several modifications to enhance generalization on transformed and unseen data:  

                        <l>
                            <li>Max Pooling: Replaced average pooling layers with max pooling. Max pooling captures stronger feature activations and is more resilient to spatial noise.  
                            <li>ReLU Activation: Replaced Tanh with ReLU to reduce vanishing gradient risk and enhance sparsity.  
                            <li>Data Normalization: Normalized pixel values to [0, 1].  
                            <li>Dropout: Added dropout layers to prevent overfitting on training data.    
                        </l>

                        <br><br>Performance on Unseen Data
                        <br>As shown in the error rate graph, LeNet2 achieved rapid initial convergence, with training error decreasing from 21% to below 8% within the first few epochs. 
                        However, the test error remained consistently low and stable, around 1.1%, indicating strong generalization performance. Unlike the first model, LeNet2 avoided overfitting, 
                        likely due to the inclusion of dropout layers and a more resilient activation/pooling strategy. The final test error was 1.1%, corresponding to a test accuracy of 98.9% on the transformed MNIST dataset.  

                        <img src="images/lenet-images/Error_Rate_Graph_2.png" alt="Training and test error rate on the modified LeNet-5">
                        <br>Figure 5: Training and Test Error (LeNet2)

                        <img src="images/lenet-images/Confusion_Matrix_2.png" alt="Confusion matrix for the modified LeNet on transformed MNIST data">
                        <br>Figure 6: Confusion Matrix for Modified LeNet on Transformed MNIST Data

                        <img src="images/lenet-images/Most_Confusing_Example_2.png" alt="Most Confusing Examples per Digit for modified model">
                        <br>Figure 7: Most Confusing Examples per Digit for Modified Model (True Label vs. Predicted Label)

                    </p>
                </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://devpost.com/software/frogspawn">frogspawn</a></h2>
                <p> 
                    WINNER of the  Best Social Good Hack at HackHers 2023! <br>
                    frogspawn is a chatbot that I made with my friends Kapila and Sabrina for the HackHers Hackathon, hosted at Rutgers University. <br>
                    The main function of the bot is to generate frogs for the user,
                    inform them on endangered frog species, and encourage people to donate to and support preservation organizations. It also has other cool features,
                    like reacting to messages with "frog" emojis. üê∏ <br>
                    <br>This project uses HTML, CSS, Javascript, GitHub, and Discord.js.
                    <br><a href="https://km776.github.io/frogspawn/">Check out the website and add the bot to your Discord server!</a>
                    <br>
                </p>
                </div>
                <img src="images/frogspawn.png">
            </div>
            <div class="project">
                <div>
                <h2>Calculate Implausible Bounds</h2>
                <p>SAP program developed for FirstEnergy Corp.<br>
                    Interacts with over 6 million records, estimated to reduce billing team manual monthly reviewing workload by 60-80%.
                    <br> <br>The goal of this project is to replicate the billing team's logic so that we can reduce their workload when 
                    they review monthly electricity usage. It will automate the process of determining "implausible" kilowatt hours of electricity usage 
                    measured by a meter. For instance, if a value is too high or too low to be realistic, the meter might be broken. To determind this, we compare it with its 
                    historical readings and calculate whether it is within plausible usage bounds.
                    <br> <br>Working with a data scientist, my goal was to experiment if it was possible to recreate his Python program in SAP, which would make it faster 
                    to retrieve data and calculate plausible meter reading bounds. For each "bin" - ex. during a certain season, in a certain location - 
                    I would take all the recorded meter readings and use percentiles to calculate the lower x% bound and higher y% bound
                    between which (y-x)% of the data fell. <br> <br>
                    Thus, rather than having each meter reading manually checked and approved by employees, the program would automate the process. <br>
                    <br>This project uses SAP ABAP and SQL queries to interact with the Oracle database.
                </p>
                </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://github.com/sanasnaik/neo-classifier">Near-Earth-Objects Predictive Classifier</a></h2>
                <p>Data 101 Final Project: used R code on a dataset to predict whether asteroids/NEOs would be classified as hazardous or non-hazardous.
                <br>What I Did: 
                <br>I used Kaggle to find a dataset I was interested in using, which was the ‚ÄúNearest Earth Objects‚Äù dataset sourced from NASA. I plotted the variables from the 
                    dataset to gain some insight into it. It had information on different asteroids and other NEOs such as their names, estimated sizes, relative velocity, 
                    miss distance, absolute magnitude, and whether or not they were classified as hazardous. I then created a decision tree using rpart for the dataset to predict
                    whether or not an asteroid would be classified as hazardous based on its characteristics. I also used naive Bayes to create predictions, and then I compared 
                    the accuracies of both methods using their confusion matrices.
                <br> This project is coded in R.
                More details on <a href="https://github.com/sanasnaik/neo-classifier">GitHub!</a>
                </p>
                <img src="images/decisiontree.png"> <br>
                <img src="images/confusionmatrices.png">
            </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://github.com/sanasnaik/Exoplanet-Eradication">Exoplanet Eradication</a></h2>
                <p> 
                    Work in progress!<br>
                    I was inspired to make this game after watching "3 Body Problem" on Netflix and learning the Dark Forest theory.
                    Basically, this game is in the perspective of a human working for a company responsible for "global security and defense".
                    As the player continues getting through each level, they learn about the true nature of their employment.
                    Each level involves real exoplanets sourced from the NASA exoplanet archive.
                    <br> This game is a personal project, and I am coding it in Python using the Pygame library. 
                    <br> This game uses TAP (Table Acccess Protocol) queries which incorporate SQL statements to access NASA databases, specifically
                    the NASA exoplanet archive.
                </p>
                <img src="images/exoplanet.png"> <br>
                <img src="images/tapquery.png">
                </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://github.com/sanasnaik/AI-TicTacToe/blob/main/TicTacToe%20AI.py">Tic-Tac-Toe Solver</a></h2>
                <p>A first step into AI and game theory. Uses the "minimax" algorithm to find the best solution for a given tic-tac-toe board.<br>
                This project is coded in Python. 
                </p>
                <img src="images/tictactoe.png">
                </div>
            </div>
            <div class="project">
                <div>
                    <h2>01:198:211 Computer Architecture</h2>
                    <p>
                        Note: While I can't post my code, as it is a violation of academic integrity policies, I can summarize my projects here.
                    <ul>
                        <li>Finding the matrix determinant + matrix exponentiation</li>
                        <li>Inserting nodes into sorted linked lists and binary search trees</li>
                        <li>Working with graphs, DFS, BFS, finding cycles, and shortest path algorithms</li>
                        <li>Programming a "cache" simulator which would store and dispose of memory according to requirements</li>
                        <li>Using GDB debugger to complete the notorious Bomblab assignment, stepping through lines of code</li>
                        <li>Converting integers and floating point numbers to binary, and vice versa, with specified constraints</li>
                    </ul>
                    <br>These projects were coded in C on a Linux Ubuntu VM.
                    </p>
                </div>
            </div>
            <div class="project">
                <div>
                <h2><a href="https://www.ebfirst.org/about-us">Team Astraea 6897 - Robotics</a></h2>
                <p> Coding Subteam 2019-2022 <br>
                    I participated as a robot programmer on my high school's FIRST (For Inspiration and Recognition of Science and Technology) robotics team. <br>
                    During my time, I learned how to gather sensor data and use Java to program motors, drivebases, and pneumatics on the bot. 
                    As a team, we collaborated on GitHub to write and test code that lets the robot run 100% autonomously.
                    I primarily programmed Ursa‚Äôs color sensors and drivebase mechanisms and mentored new members during the summer.
                    <br> <a href="https://github.com/sanasnaik/LunaBot">Here's an example of one of my beginner projects.</a>
                    <br> This project is coded in Java.
                    <br> P.S. I'm pictured on the left-most side of this image!
                </p>
                </div>
                <img src="images/astraea.jpg">
            </div>
        </div>
        <div class="copyright">
            Coded by Sana Naik.
        </div>
    </body>
</html>